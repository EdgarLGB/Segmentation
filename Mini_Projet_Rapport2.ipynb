{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Projet Multimédia: Segementation audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Becko Camara; Guobao LI; Rongbo Liu; Shiting LI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But: \n",
    "      Rconnaissance de locuteurs dans une bande audio et détection de changement de locuteurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données: \n",
    "               Bande audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outils:\n",
    "          1. pyAudioAnalysis\n",
    "          2. Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Concepiton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Determiner la taille de la fênetre et la taille du bloc.\n",
    "\n",
    "- Feature extraction. \n",
    "On utilise stFeatureExtraction() de pyAudioAnalysis pour extraire le court terme feature séquences pour un signal audio, en utilisant une taille de frame de 50 ms et une taille de étape de 25 ms. Pour pouvoir lire les échantillons audio, nous applelons la fonction readAudioFile() du fichier audioBasicIO.py.\n",
    "\n",
    "- Calculer les MFCCs (Mel Frequency Cepstrum Coefficient). \n",
    "Fréquence mel est proposée sur la base des caractéristiques auditives humaines, il y a une correspondance non linéaire entre féquence mel et fréquence Hz. Mel Frequency Cepstral Coefficients (MFCC) est l'utilisation d'une telle relation entre eux, calculer les caractéristiques des spectrales HZ. Nous avons donc utilisé MFCC pour la reconnaissance vocale.\n",
    "\n",
    "- Calculer la distribution de gauss des deux blocs consécutifs\n",
    "\n",
    "- On combine ces deux blocs, et on calcule la distribution de gauss du bloc combiné\n",
    "\n",
    "- On stocke le résultat dans le tableaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Realisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le réalisation de  code python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import audioFeatureExtraction\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import des dépendances et les bibliothèques néssaires:\n",
    "\n",
    "- audioBasicIO\n",
    "\n",
    "- audioFeatureExtraction\n",
    "\n",
    "- numpy(stockage et manutention des grandes matrices)\n",
    "\n",
    "- math\n",
    "\n",
    "- matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main process\n",
    "[Fs, x] = audioBasicIO.readAudioFile(\"data/diarizationExample.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- audioBasicIO.readAudioFile(path)\n",
    "Cette fonction retourne un tableau numpy qui stocke l'échantillon audio d'un WAV.\n",
    "\n",
    "*Il y a une warnning ici car le format de wav.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TIME_OF_WINDOW = 0.050\t#a window = 0.05s\n",
    "TIME_OF_STEP = 0.025\t\t#step = 0.01s\n",
    "SIZE_OF_WINDOW = int(TIME_OF_WINDOW * Fs)\t#the number of frame for one window\n",
    "SIZE_OF_STEP = int(TIME_OF_STEP * Fs)\t\t#the number of frame for one step\n",
    "BLOCK_SIZE = 4\t\t#a block has (6 * SIZE_OF_STEP) frame\n",
    "BLOCK_STEP = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Determiner le fênetre et le bloc\n",
    "\n",
    "- Une taille de fenêtre de 50 ms et une étape de 25 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variables \n",
    "END_OF_FILE = 0\n",
    "FIRST_PAIR = 1\n",
    "INDEX_BOUCLE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getMFCCs(block_start, block_end):\n",
    "\treturn attribute[8:20,block_start:block_end+1]\n",
    "\n",
    "def getMFCCsFromTime(moment_start, moment_end):\n",
    "\tblock_start = int(moment_start / BLOCK_STEP / TIME_OF_STEP - 1)\n",
    "\tblock_end = int(moment_end / BLOCK_STEP / TIME_OF_STEP - 1)\n",
    "\treturn getMFCCs(block_start, block_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Calculer les MFCCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gauss(x, mean, cov):\n",
    "\t[n, d] = x.shape\n",
    "\t[j, k] = cov.shape\n",
    "\tif (j != n) | (k != n):\n",
    "\t\traise Exception(\"Dimension of the covariance matrix and data should match\")\n",
    "\tinvcov = cov.T\n",
    "\tmean = np.reshape(mean, (1, n))\n",
    "\n",
    "\tx = x - (np.ones((d, 1))*mean).T\n",
    "\tfact = np.sum(((np.dot(invcov, x))*x), axis = 1)\n",
    "\n",
    "\ty = np.exp(-0.5*fact)\n",
    "\n",
    "\ty = np.divide(y, math.pow((2*math.pi), n)*np.std(cov))\n",
    "\n",
    "\treturn y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Définir la méthode de Gauss pour calculer la distribution de gauss des deux blocs consécutifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature extraction from the library pyAudioAnalysis\n",
    "attribute = audioFeatureExtraction.stFeatureExtraction(x, Fs, SIZE_OF_WINDOW, SIZE_OF_STEP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature extraction\n",
    "\n",
    "- stFeatureExtraction()\n",
    "pour extraire les courtes terme feature séquencesde pour un signal audio, en utilisant une taille de frame de 50 ms et une étape de frame de 25 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# relationship between the similarity and the timestamp in the audio\n",
    "relation = [[1 for col in range(2)] for row in range(attribute.shape[1]/BLOCK_STEP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while (END_OF_FILE == 0):\n",
    "\tif (FIRST_PAIR == 1):\n",
    "\t\t# for the first part of the block\n",
    "\t\tblock_i_index_start = 0\n",
    "\t\tblock_i_index_end = BLOCK_SIZE\n",
    "\t\tblock_i_attribute = getMFCCs(block_i_index_start, block_i_index_end)\n",
    "\n",
    "\n",
    "\t\tblock_i_mean = np.mean(block_i_attribute, axis=1)\n",
    "\t\tblock_i_cov = np.cov(block_i_attribute)\n",
    "\t\tblock_i_log_like = np.log(gauss(block_i_attribute, mean=block_i_mean, cov=block_i_cov))\n",
    "\n",
    "\n",
    "\n",
    "\t\tblock_j_index_start = block_i_index_end + 1\n",
    "\t\tblock_j_index_end = block_j_index_start + BLOCK_SIZE - 1\n",
    "\t\tblock_j_attribute = getMFCCs(block_j_index_start, block_j_index_end)\n",
    "\n",
    "\n",
    "\t\tblock_j_mean = np.mean(block_j_attribute, axis=1)\n",
    "\t\tblock_j_cov = np.cov(block_j_attribute)\n",
    "\t\tblock_j_log_like = np.log(gauss(block_j_attribute, mean=block_j_mean, cov=block_j_cov))\n",
    "\n",
    "\n",
    "\t\tFIRST_PAIR = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Processus de calcul pour la première partie d'un bloc.\n",
    "\n",
    "- On calcule les MFCCs de block_i, ensuite on calcule la valeur moyenne des MFCCs, la valeur de covariance des MFCCs, la valeur de Gausse entre les MFCCs, la valeur moyenne des MFCCs et la valeur de covariance des MFCCs.\n",
    "\n",
    "- Pour le block_j, on fait les mêmes calculs comme block_i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\telse:\n",
    "\t\t#for the rest of the block\n",
    "\t\tblock_j_index_start += BLOCK_STEP\n",
    "\t\tblock_j_index_end += BLOCK_STEP\n",
    "\n",
    "\t\tnew_attribute = getMFCCs(block_j_index_end-BLOCK_STEP+1, block_j_index_end)\n",
    "\n",
    "\t\t#the following code is for the object that to avoid recalculate the overlap between the block after moved and before moved\n",
    "\t\tblock_i_index_start += BLOCK_STEP\n",
    "\t\tblock_i_index_end += BLOCK_STEP\n",
    "\t\tblock_i_attribute[:,0:block_i_attribute.shape[1]-new_attribute.shape[1]] = block_i_attribute[:,new_attribute.shape[1]:block_i_attribute.shape[1]]\n",
    "\t\tblock_i_attribute[:,block_i_attribute.shape[1]-new_attribute.shape[1]:block_i_attribute.shape[1]] = block_j_attribute[:,0:new_attribute.shape[1]]\n",
    "\n",
    "\t\tblock_i_mean = np.mean(block_i_attribute, axis=1)\n",
    "\t\tblock_i_cov = np.cov(block_i_attribute)\n",
    "\t\tblock_i_log_like = np.log(gauss(block_i_attribute, mean=block_i_mean, cov=block_i_cov))\n",
    "\n",
    "\n",
    "\t\tblock_j_attribute[:,0:block_j_attribute.shape[1]-new_attribute.shape[1]] = block_j_attribute[:,new_attribute.shape[1]:block_j_attribute.shape[1]]\n",
    "\t\tblock_j_attribute[:,block_j_attribute.shape[1]-new_attribute.shape[1]:block_j_attribute.shape[1]] = new_attribute[:,0:new_attribute.shape[1]]\n",
    "\n",
    "\t\tblock_j_mean = np.mean(block_j_attribute, axis=1)\n",
    "\t\tblock_j_cov = np.cov(block_j_attribute)\n",
    "\t\tblock_j_log_like = np.log(gauss(block_j_attribute, mean=block_j_mean, cov=block_j_cov))\n",
    "\n",
    "\n",
    "\tblock_union_index_start = block_i_index_start\n",
    "\tblock_union_index_end = block_j_index_end\n",
    "\tblock_union_attribute = np.concatenate((block_i_attribute, block_j_attribute), axis = 1)\n",
    "\tblock_union_mean = np.mean(block_union_attribute, axis=1)\n",
    "\tblock_union_cov = np.cov(block_union_attribute)\n",
    "\tblock_union_log_like = np.log(gauss(block_union_attribute, mean=block_union_mean, cov=block_union_cov))\n",
    "\n",
    "\trelation[INDEX_BOUCLE-1][0] = np.sum(block_i_log_like) + np.sum(block_j_log_like) - np.sum(block_union_log_like)\n",
    "\trelation[INDEX_BOUCLE-1][1] = (block_i_index_end + block_j_index_start) / 2 * TIME_OF_STEP\n",
    "\n",
    "\n",
    "\tINDEX_BOUCLE += 1\n",
    "\n",
    "\tif block_j_index_end + BLOCK_STEP > attribute.shape[1]:\n",
    "\t\tEND_OF_FILE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On continue à faire les calculs pour la restante partie de bloc.\n",
    "\n",
    "- Nous avons constamment procédé alternatif pour éviter les calculs répétitifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cut the audio\n",
    "relation_cut = filter(lambda t: t[0] > 0, relation)\n",
    "\n",
    "for item in relation_cut:\n",
    "\tprint item\n",
    "\n",
    "\n",
    "\n",
    "# print getMFCCsFromTime(0.4, 4.0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Couper l'audio et délivre le résultat.\n",
    "\n",
    "- Si la valeur de Gauss est négative, c'est-à-dire que ce clip d'audio est la même personne comme le fragment précédent. Et si ls valeur de Gauss est positive, c'est-à-dire que ce clip d'audio n'est pas la même personne comme le fragment précédent, on va faire une coupe ici.\n",
    "\n",
    "- Nous ignorons tous les valeurs de Gauss négatives, seule interceptons les valeurs de Gauss positives.\n",
    "\n",
    "- Pour le resultat [x, y], x est le résultat de la mise en oeuvre de Gauss, y est le point de temps de couper l'audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reconnaissance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.1 Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Le conception de faire une reconnaissance est utiliser k-means pour mettre les block similaire ensemble.\n",
    "- Le premier fonction **euclDistance(vector1, vector2)** est calculer la distance entre deux vector.\n",
    "- Le deuxième foction **initCentroids(dataSet, k)** est obtenir k centres sur le data. **k** est le nombre de class. Dans ce projet, le nombre de class est le nombre des locuteurs.\n",
    "- Le troisième fonction **kmeans(dataSet, k)** est utiliser le distance Euclidean pour mettre les points ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#===========Kmeans Definition=====================\n",
    "#calculate Euclidean distance\n",
    "def euclDistance(vector1, vector2):\n",
    "\treturn sqrt(sum(power(vector2 - vector1, 2)))\n",
    "\n",
    "# init centroids with random samples\n",
    "def initCentroids(dataSet, k):\n",
    "\tnumSamples, dim = dataSet.shape\n",
    "\tcentroids = zeros((k, dim))\n",
    "\tfor i in range(k):\n",
    "\t\tindex = int(random.uniform(0, numSamples))\n",
    "\t\tcentroids[i, :] = dataSet[index, :]\n",
    "\treturn centroids\n",
    "\n",
    "# k-means cluster\n",
    "def kmeans(dataSet, k):\n",
    "\tnumSamples = dataSet.shape[0]\n",
    "\t# first column stores which cluster this sample belongs to,\n",
    "\t# second column stores the error between this sample and its centroid\n",
    "\tclusterAssment = mat(zeros((numSamples, 2)))\n",
    "\tclusterChanged = True\n",
    "\n",
    "\t## step 1: init centroids\n",
    "\tcentroids = initCentroids(dataSet, k)\n",
    "\n",
    "\twhile clusterChanged:\n",
    "\t\tclusterChanged = False\n",
    "\t\t## for each sample\n",
    "\t\tfor i in xrange(numSamples):\n",
    "\t\t\tminDist  = 100000.0\n",
    "\t\t\tminIndex = 0\n",
    "\t\t\t## for each centroid\n",
    "\t\t\t## step 2: find the centroid who is closest\n",
    "\t\t\tfor j in range(k):\n",
    "\t\t\t\tdistance = euclDistance(centroids[j, :], dataSet[i, :])\n",
    "\t\t\t\tif distance < minDist:\n",
    "\t\t\t\t\tminDist  = distance\n",
    "\t\t\t\t\tminIndex = j\n",
    "\n",
    "\t\t\t## step 3: update its cluster\n",
    "\t\t\tif clusterAssment[i, 0] != minIndex:\n",
    "\t\t\t\tclusterChanged = True\n",
    "\t\t\t\tclusterAssment[i, :] = minIndex, minDist**2\n",
    "\n",
    "\t\t## step 4: update centroids\n",
    "\t\tfor j in range(k):\n",
    "\t\t\tpointsInCluster = dataSet[nonzero(clusterAssment[:, 0].A == j)[0]]\n",
    "\t\t\tcentroids[j, :] = mean(pointsInCluster, axis = 0)\n",
    "\n",
    "\tprint 'cluster complete!'\n",
    "\treturn centroids, clusterAssment\n",
    "\n",
    "def abs(input):\n",
    "\tif input <0 : return - input\n",
    "\telse : return input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dans cette étap, on d'abord créer une novelle liste *temprelation* qui prendre le premier colonne de relation_cut et ajouter un deuxième colonne qui a des valeurs égal 1. \n",
    "\n",
    "- Ensuite, on transmettre cette liste à une matrice par utilise ```dataSet= mat(dataSet)```.\n",
    "\n",
    "- Enfin, on utlise cette matrice pour calculer les centres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temprelation = []\n",
    "for i in range(len(relation_cut)-3): #-3 because the last 3 numbers are meaningless\n",
    "    temprelation.append([relation_cut[i][0],1])\n",
    "\n",
    "#temprelation is a list which takes only first colum of relation_cut and add another colum which values are all 1\n",
    "#This action alow to transefer the MFCC to a 2-dimension data which use for cluster\n",
    "\n",
    "\n",
    "## step 1: load data\n",
    "print \"step 1: load data...\"\n",
    "dataSet = temprelation\n",
    "\n",
    "\n",
    "# step 2: clustering...\n",
    "print \"step 2: clustering...\"\n",
    "dataSet = mat(dataSet)\n",
    "k = 4\n",
    "centroids, clusterAssment = kmeans(dataSet, k)\n",
    "classification =[]\n",
    "for indexi in range(k):\n",
    "\tclassification .append(centroids[indexi][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pour chaque block, on calculer le distance avec le centre et le point, et marker different locuteur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## step 3: Mark speaker to each block\n",
    "relation_cut_regonize = [] #This list is to store the information with different speakers\n",
    "for indexj in range(len(dataSet)):\n",
    "\tmin1 = abs(relation_cut[indexj][0]-classification[0])\n",
    "\tmin2 = abs(relation_cut[indexj][0]-classification[1])\n",
    "\tmin3 = abs(relation_cut[indexj][0]-classification[2])\n",
    "\tmin4 = abs(relation_cut[indexj][0]-classification[3])\n",
    "\tif min1<min2 and min1 < min3 and min1<min4:\n",
    "\t\trelation_cut_regonize.append([relation_cut[indexj],\"Speaker1\"])\n",
    "\telse:\n",
    "\t\tif min2<min1 and min2 < min3 and min2<min4:\n",
    "\t\t\trelation_cut_regonize.append([relation_cut[indexj],\"Speaker2\"])\n",
    "\t\telse:\n",
    "\t\t\tif min3<min1 and min3 < min2 and min3<min4:\n",
    "\t\t\t\trelation_cut_regonize.append([relation_cut[indexj],\"Speak3\"])\n",
    "\t\t\telse:\n",
    "\t\t\t\tif min4<min1 and min4 < min2 and min4<min3:\n",
    "\t\t\t\t\trelation_cut_regonize.append([relation_cut[indexj],\"Speak4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On afficher le result de reconnaissance avec une iterateur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#step4: shows the result\n",
    "print \"=========The data after regonizing as 4 speakers===========\"\n",
    "for item in relation_cut_regonize:\n",
    "\tprint item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.  Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce mini-projet, on etudier comment traite une fichier en wav format pour avoir une segamatation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
