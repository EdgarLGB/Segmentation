{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Projet Multimédia: Segementation audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Becko Camara; Guobao LI; Rongbo Liu; Shiting LI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But: \n",
    "      Rconnaissance de locuteurs dans une bande audio et détection de changement de locuteurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données: \n",
    "               Bande audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outils:\n",
    "          1. pyAudioAnalysis\n",
    "          2. Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Concepiton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Determiner la taille de la fênetre et la taille du bloc.\n",
    "\n",
    "-Feature extraction. On utilise stFeatureExtraction() de pyAudioAnalysis pour extraire le court terme feature séquences pour un signal audio, en utilisant une taille de frame de 50 ms et une taille de étape de 25 ms. Pour pouvoir lire les échantillons audio, nous applelons la fonction readAudioFile() du fichier audioBasicIO.py.\n",
    "\n",
    "-Calculer les MFCCs (Mel Frequency Cepstrum Coefficient). Fréquence mel est proposée sur la base des caractéristiques auditives humaines, il y a une correspondance non linéaire entre féquence mel et fréquence Hz. Mel Frequency Cepstral Coefficients (MFCC) est l'utilisation d'une telle relation entre eux, calculer les caractéristiques des spectrales HZ. Nous avons donc utilisé MFCC pour la reconnaissance vocale.\n",
    "\n",
    "-Calculer la distribution de gauss des deux blocs consécutifs\n",
    "\n",
    "-On combine ces deux blocs, et on calcule la distribution de gauss du bloc combiné\n",
    "\n",
    "-On stocke le résultat dans le tableaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Realisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le réalisation de  code python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import audioFeatureExtraction\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import des dépendances et les bibliothèques néssaires:\n",
    "\n",
    "-audioBasicIO\n",
    "\n",
    "-audioFeatureExtraction\n",
    "\n",
    "-numpy(stockage et manutention des grandes matrices)\n",
    "\n",
    "-math\n",
    "\n",
    "-matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main process\n",
    "[Fs, x] = audioBasicIO.readAudioFile(\"data/diarizationExample.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-audioBasicIO.readAudioFile(path): Cette fonction retourne un tableau numpy qui stocke l'échantillon audio d'un WAV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TIME_OF_WINDOW = 0.050\t#a window = 0.05s\n",
    "TIME_OF_STEP = 0.025\t\t#step = 0.01s\n",
    "SIZE_OF_WINDOW = int(TIME_OF_WINDOW * Fs)\t#the number of frame for one window\n",
    "SIZE_OF_STEP = int(TIME_OF_STEP * Fs)\t\t#the number of frame for one step\n",
    "BLOCK_SIZE = 4\t\t#a block has (6 * SIZE_OF_STEP) frame\n",
    "BLOCK_STEP = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Determiner le fênetre et le bloc\n",
    "\n",
    "-Une taille de fenêtre de 50 ms et une étape de 25 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables \n",
    "END_OF_FILE = 0\n",
    "FIRST_PAIR = 1\n",
    "INDEX_BOUCLE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMFCCs(block_start, block_end):\n",
    "\treturn attribute[8:20,block_start:block_end+1]\n",
    "\n",
    "def getMFCCsFromTime(moment_start, moment_end):\n",
    "\tblock_start = int(moment_start / BLOCK_STEP / TIME_OF_STEP - 1)\n",
    "\tblock_end = int(moment_end / BLOCK_STEP / TIME_OF_STEP - 1)\n",
    "\treturn getMFCCs(block_start, block_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-Calculer les MFCCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss(x, mean, cov):\n",
    "\t[n, d] = x.shape\n",
    "\t[j, k] = cov.shape\n",
    "\tif (j != n) | (k != n):\n",
    "\t\traise Exception(\"Dimension of the covariance matrix and data should match\")\n",
    "\tinvcov = cov.T\n",
    "\tmean = np.reshape(mean, (1, n))\n",
    "\n",
    "\tx = x - (np.ones((d, 1))*mean).T\n",
    "\tfact = np.sum(((np.dot(invcov, x))*x), axis = 1)\n",
    "\n",
    "\ty = np.exp(-0.5*fact)\n",
    "\n",
    "\ty = np.divide(y, math.pow((2*math.pi), n)*np.std(cov))\n",
    "\n",
    "\treturn y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Définir la méthode de Gauss pour calculer la distribution de gauss des deux blocs consécutifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature extraction from the library pyAudioAnalysis\n",
    "attribute = audioFeatureExtraction.stFeatureExtraction(x, Fs, SIZE_OF_WINDOW, SIZE_OF_STEP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Feature extraction\n",
    "\n",
    "-stFeatureExtraction(): pour extraire les courtes terme feature séquencesde pour un signal audio, en utilisant une taille de frame de 50 ms et une étape de frame de 25 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# relationship between the similarity and the timestamp in the audio\n",
    "relation = [[1 for col in range(2)] for row in range(attribute.shape[1]/BLOCK_STEP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while (END_OF_FILE == 0):\n",
    "\tif (FIRST_PAIR == 1):\n",
    "\t\t# for the first part of the block\n",
    "\t\tblock_i_index_start = 0\n",
    "\t\tblock_i_index_end = BLOCK_SIZE\n",
    "\t\tblock_i_attribute = getMFCCs(block_i_index_start, block_i_index_end)\n",
    "\n",
    "\n",
    "\t\tblock_i_mean = np.mean(block_i_attribute, axis=1)\n",
    "\t\tblock_i_cov = np.cov(block_i_attribute)\n",
    "\t\tblock_i_log_like = np.log(gauss(block_i_attribute, mean=block_i_mean, cov=block_i_cov))\n",
    "\n",
    "\n",
    "\n",
    "\t\tblock_j_index_start = block_i_index_end + 1\n",
    "\t\tblock_j_index_end = block_j_index_start + BLOCK_SIZE - 1\n",
    "\t\tblock_j_attribute = getMFCCs(block_j_index_start, block_j_index_end)\n",
    "\n",
    "\n",
    "\t\tblock_j_mean = np.mean(block_j_attribute, axis=1)\n",
    "\t\tblock_j_cov = np.cov(block_j_attribute)\n",
    "\t\tblock_j_log_like = np.log(gauss(block_j_attribute, mean=block_j_mean, cov=block_j_cov))\n",
    "\n",
    "\n",
    "\t\tFIRST_PAIR = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Processus de calcul pour la première partie d'un bloc.\n",
    "\n",
    "-On calcule les MFCCs de block_i, ensuite on calcule la valeur moyenne des MFCCs, la valeur de covariance des MFCCs, la valeur de Gausse entre les MFCCs, la valeur moyenne des MFCCs et la valeur de covariance des MFCCs.\n",
    "\n",
    "-Pour le block_j, on fait les mêmes calculs comme block_i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\telse:\n",
    "\t\t#for the rest of the block\n",
    "\t\tblock_j_index_start += BLOCK_STEP\n",
    "\t\tblock_j_index_end += BLOCK_STEP\n",
    "\n",
    "\t\tnew_attribute = getMFCCs(block_j_index_end-BLOCK_STEP+1, block_j_index_end)\n",
    "\n",
    "\t\t#the following code is for the object that to avoid recalculate the overlap between the block after moved and before moved\n",
    "\t\tblock_i_index_start += BLOCK_STEP\n",
    "\t\tblock_i_index_end += BLOCK_STEP\n",
    "\t\tblock_i_attribute[:,0:block_i_attribute.shape[1]-new_attribute.shape[1]] = block_i_attribute[:,new_attribute.shape[1]:block_i_attribute.shape[1]]\n",
    "\t\tblock_i_attribute[:,block_i_attribute.shape[1]-new_attribute.shape[1]:block_i_attribute.shape[1]] = block_j_attribute[:,0:new_attribute.shape[1]]\n",
    "\n",
    "\t\tblock_i_mean = np.mean(block_i_attribute, axis=1)\n",
    "\t\tblock_i_cov = np.cov(block_i_attribute)\n",
    "\t\tblock_i_log_like = np.log(gauss(block_i_attribute, mean=block_i_mean, cov=block_i_cov))\n",
    "\n",
    "\n",
    "\t\tblock_j_attribute[:,0:block_j_attribute.shape[1]-new_attribute.shape[1]] = block_j_attribute[:,new_attribute.shape[1]:block_j_attribute.shape[1]]\n",
    "\t\tblock_j_attribute[:,block_j_attribute.shape[1]-new_attribute.shape[1]:block_j_attribute.shape[1]] = new_attribute[:,0:new_attribute.shape[1]]\n",
    "\n",
    "\t\tblock_j_mean = np.mean(block_j_attribute, axis=1)\n",
    "\t\tblock_j_cov = np.cov(block_j_attribute)\n",
    "\t\tblock_j_log_like = np.log(gauss(block_j_attribute, mean=block_j_mean, cov=block_j_cov))\n",
    "\n",
    "\n",
    "\tblock_union_index_start = block_i_index_start\n",
    "\tblock_union_index_end = block_j_index_end\n",
    "\tblock_union_attribute = np.concatenate((block_i_attribute, block_j_attribute), axis = 1)\n",
    "\tblock_union_mean = np.mean(block_union_attribute, axis=1)\n",
    "\tblock_union_cov = np.cov(block_union_attribute)\n",
    "\tblock_union_log_like = np.log(gauss(block_union_attribute, mean=block_union_mean, cov=block_union_cov))\n",
    "\n",
    "\trelation[INDEX_BOUCLE-1][0] = np.sum(block_i_log_like) + np.sum(block_j_log_like) - np.sum(block_union_log_like)\n",
    "\trelation[INDEX_BOUCLE-1][1] = (block_i_index_end + block_j_index_start) / 2 * TIME_OF_STEP\n",
    "\n",
    "\n",
    "\tINDEX_BOUCLE += 1\n",
    "\n",
    "\tif block_j_index_end + BLOCK_STEP > attribute.shape[1]:\n",
    "\t\tEND_OF_FILE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-On continue à faire les calculs pour la restante partie de bloc.\n",
    "\n",
    "-Nous avons constamment procédé alternatif pour éviter les calculs répétitifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cut the audio\n",
    "relation_cut = filter(lambda t: t[0] > 0, relation)\n",
    "\n",
    "for item in relation_cut:\n",
    "\tprint item\n",
    "\n",
    "\n",
    "\n",
    "# print getMFCCsFromTime(0.4, 4.0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Couper l'audio et délivre le résultat.\n",
    "\n",
    "-Si la valeur de Gauss est négative, c'est-à-dire que ce clip d'audio est la même personne comme le fragment précédent. Et si ls valeur de Gauss est positive, c'est-à-dire que ce clip d'audio n'est pas la même personne comme le fragment précédent, on va faire une coupe ici.\n",
    "\n",
    "-Nous ignorons tous les valeurs de Gauss négatives, seule interceptons les valeurs de Gauss positives.\n",
    "\n",
    "-Pour le resultat [x, y], x est le résultat de la mise en oeuvre de Gauss, y est le point de temps de couper l'audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reconnaissance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.  Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
