{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Projet Multimédia: Segementation audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Becko Camara; Guobao LI; Rongbo Liu; Shiting LI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But: \n",
    "      Rconnaissance de locuteurs dans une bande audio et détection de changement de locuteurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données: \n",
    "               Bande audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outils:\n",
    "          1. pyAudioAnalysis\n",
    "          2. Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Concepiton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##balabala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Realisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le réalisation de  code python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import audioFeatureExtraction\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main process\n",
    "[Fs, x] = audioBasicIO.readAudioFile(\"data/diarizationExample.wav\")\n",
    "\n",
    "TIME_OF_WINDOW = 0.050\t#a window = 0.05s\n",
    "TIME_OF_STEP = 0.025\t\t#step = 0.01s\n",
    "SIZE_OF_WINDOW = int(TIME_OF_WINDOW * Fs)\t#the number of frame for one window\n",
    "SIZE_OF_STEP = int(TIME_OF_STEP * Fs)\t\t#the number of frame for one step\n",
    "BLOCK_SIZE = 4\t\t#a block has (6 * SIZE_OF_STEP) frame\n",
    "BLOCK_STEP = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables \n",
    "END_OF_FILE = 0\n",
    "FIRST_PAIR = 1\n",
    "INDEX_BOUCLE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMFCCs(block_start, block_end):\n",
    "\treturn attribute[8:20,block_start:block_end+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMFCCsFromTime(moment_start, moment_end):\n",
    "\tblock_start = int(moment_start / BLOCK_STEP / TIME_OF_STEP - 1)\n",
    "\tblock_end = int(moment_end / BLOCK_STEP / TIME_OF_STEP - 1)\n",
    "\treturn getMFCCs(block_start, block_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss(x, mean, cov):\n",
    "\t[n, d] = x.shape\n",
    "\t[j, k] = cov.shape\n",
    "\tif (j != n) | (k != n):\n",
    "\t\traise Exception(\"Dimension of the covariance matrix and data should match\")\n",
    "\tinvcov = cov.T\n",
    "\tmean = np.reshape(mean, (1, n))\n",
    "\n",
    "\tx = x - (np.ones((d, 1))*mean).T\n",
    "\tfact = np.sum(((np.dot(invcov, x))*x), axis = 1)\n",
    "\n",
    "\ty = np.exp(-0.5*fact)\n",
    "\n",
    "\ty = np.divide(y, math.pow((2*math.pi), n)*np.std(cov))\n",
    "\n",
    "\treturn y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature extraction from the library pyAudioAnalysis\n",
    "attribute = audioFeatureExtraction.stFeatureExtraction(x, Fs, SIZE_OF_WINDOW, SIZE_OF_STEP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# relationship between the similarity and the timestamp in the audio\n",
    "relation = [[1 for col in range(2)] for row in range(attribute.shape[1]/BLOCK_STEP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while (END_OF_FILE == 0):\n",
    "\tif (FIRST_PAIR == 1):\n",
    "\t\t# for the first pari of the block\n",
    "\t\tblock_i_index_start = 0\n",
    "\t\tblock_i_index_end = BLOCK_SIZE\n",
    "\t\tblock_i_attribute = getMFCCs(block_i_index_start, block_i_index_end)\n",
    "\n",
    "\n",
    "\t\tblock_i_mean = np.mean(block_i_attribute, axis=1)\n",
    "\t\tblock_i_cov = np.cov(block_i_attribute)\n",
    "\t\tblock_i_log_like = np.log(gauss(block_i_attribute, mean=block_i_mean, cov=block_i_cov))\n",
    "\n",
    "\n",
    "\n",
    "\t\tblock_j_index_start = block_i_index_end + 1\n",
    "\t\tblock_j_index_end = block_j_index_start + BLOCK_SIZE - 1\n",
    "\t\tblock_j_attribute = getMFCCs(block_j_index_start, block_j_index_end)\n",
    "\n",
    "\n",
    "\t\tblock_j_mean = np.mean(block_j_attribute, axis=1)\n",
    "\t\tblock_j_cov = np.cov(block_j_attribute)\n",
    "\t\tblock_j_log_like = np.log(gauss(block_j_attribute, mean=block_j_mean, cov=block_j_cov))\n",
    "\n",
    "\n",
    "\t\tFIRST_PAIR = 0\n",
    "\telse:\n",
    "\t\t#for the rest of the block\n",
    "\t\tblock_j_index_start += BLOCK_STEP\n",
    "\t\tblock_j_index_end += BLOCK_STEP\n",
    "\n",
    "\t\tnew_attribute = getMFCCs(block_j_index_end-BLOCK_STEP+1, block_j_index_end)\n",
    "\n",
    "\t\t#the following code is for the object that to avoid recalculate the overlap between the block after moved and before moved\n",
    "\t\tblock_i_index_start += BLOCK_STEP\n",
    "\t\tblock_i_index_end += BLOCK_STEP\n",
    "\t\tblock_i_attribute[:,0:block_i_attribute.shape[1]-new_attribute.shape[1]] = block_i_attribute[:,new_attribute.shape[1]:block_i_attribute.shape[1]]\n",
    "\t\tblock_i_attribute[:,block_i_attribute.shape[1]-new_attribute.shape[1]:block_i_attribute.shape[1]] = block_j_attribute[:,0:new_attribute.shape[1]]\n",
    "\n",
    "\t\tblock_i_mean = np.mean(block_i_attribute, axis=1)\n",
    "\t\tblock_i_cov = np.cov(block_i_attribute)\n",
    "\t\tblock_i_log_like = np.log(gauss(block_i_attribute, mean=block_i_mean, cov=block_i_cov))\n",
    "\n",
    "\n",
    "\t\tblock_j_attribute[:,0:block_j_attribute.shape[1]-new_attribute.shape[1]] = block_j_attribute[:,new_attribute.shape[1]:block_j_attribute.shape[1]]\n",
    "\t\tblock_j_attribute[:,block_j_attribute.shape[1]-new_attribute.shape[1]:block_j_attribute.shape[1]] = new_attribute[:,0:new_attribute.shape[1]]\n",
    "\n",
    "\t\tblock_j_mean = np.mean(block_j_attribute, axis=1)\n",
    "\t\tblock_j_cov = np.cov(block_j_attribute)\n",
    "\t\tblock_j_log_like = np.log(gauss(block_j_attribute, mean=block_j_mean, cov=block_j_cov))\n",
    "\n",
    "\n",
    "\tblock_union_index_start = block_i_index_start\n",
    "\tblock_union_index_end = block_j_index_end\n",
    "\tblock_union_attribute = np.concatenate((block_i_attribute, block_j_attribute), axis = 1)\n",
    "\tblock_union_mean = np.mean(block_union_attribute, axis=1)\n",
    "\tblock_union_cov = np.cov(block_union_attribute)\n",
    "\tblock_union_log_like = np.log(gauss(block_union_attribute, mean=block_union_mean, cov=block_union_cov))\n",
    "\n",
    "\trelation[INDEX_BOUCLE-1][0] = np.sum(block_i_log_like) + np.sum(block_j_log_like) - np.sum(block_union_log_like)\n",
    "\trelation[INDEX_BOUCLE-1][1] = (block_i_index_end + block_j_index_start) / 2 * TIME_OF_STEP\n",
    "\n",
    "\n",
    "\tINDEX_BOUCLE += 1\n",
    "\n",
    "\tif block_j_index_end + BLOCK_STEP > attribute.shape[1]:\n",
    "\t\tEND_OF_FILE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193.04016786970868, 0.1]\n",
      "[322.80179095213964, 0.15000000000000002]\n",
      "[48.618235376979669, 3.75]\n",
      "[206.06284495930311, 3.8000000000000003]\n",
      "[264.46484990545093, 5.800000000000001]\n",
      "[399.62976041628497, 6.7]\n",
      "[185.27945423237873, 6.75]\n",
      "[77.58484185258385, 11.05]\n",
      "[55.7106174875737, 12.700000000000001]\n",
      "[86.606563878601378, 13.100000000000001]\n",
      "[65.574334156685495, 16.6]\n",
      "[25.698883507655694, 18.75]\n",
      "[119.17666505648083, 18.85]\n",
      "[157.12783806256266, 18.900000000000002]\n",
      "[82.460244094641666, 24.5]\n",
      "[10.571385024471169, 25.150000000000002]\n",
      "[1.5434625659503354, 25.25]\n",
      "[211.66294698210436, 34.2]\n",
      "[70.795005105859445, 34.35]\n",
      "[100.16974802846812, 34.4]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n"
     ]
    }
   ],
   "source": [
    "# cut the audio\n",
    "relation_cut = filter(lambda t: t[0] > 0, relation)\n",
    "\n",
    "for item in relation_cut:\n",
    "\tprint item\n",
    "\n",
    "\n",
    "\n",
    "# print getMFCCsFromTime(0.4, 4.0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reconnaissance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.  Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
